## 缓存与分布式锁

### 一、缓存

#### 1.缓存使用

```
了系统性能的提升，我们一般都会将部分数据放入缓存中，加速访问。而 db 承担数据落盘工作。
```

##### 哪些数据适合放入缓存？

![image-20220609101330256](https://raw.githubusercontent.com/lilu188011/img-repo/master/image-20220609101330256.png)

- **即时性、数据一致性要求不高的**
- **访问量大且更新频率不高的数据（读多，写少）**

举例：电商类应用，商品分类，商品列表等适合缓存并加一个失效时间(根据数据更新频率来定)，后台如果发布一个商品，买家需要 5 分钟才能看到新的商品一般还是可以接受的。

![img](https://raw.githubusercontent.com/lilu188011/img-repo/master/54bf188f532448b7919b9914f2f5cbf3.gif)

#### 2.整合 redis **作为缓存**

- 引入 redis-starter

```xml
<!-- redis -->
<dependency>
 <groupId>org.springframework.boot</groupId>
 <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>

```

- 配置 redis

```yaml
spring:
  redis:
    host: 192.168.163.131
    port: 6379

```

- 使用 RedisTemplate 操作 redis

```
    @Autowired
    StringRedisTemplate stringRedisTemplate;

    @Test
    public void teststringRedisTemplate(){
        ValueOperations<String, String> ops = stringRedisTemplate.opsForValue();
        ops.set("1", "2" + UUID.randomUUID().toString());
        System.out.println(ops.get("1"));
    }

```

- 给业务中加入缓存

```java
  	@Autowired
    private StringRedisTemplate redisTemplate;

	//TODO 产生堆外内存溢出：OutOfDirectMemoryError
    //1).sprignboot2.0以后默认是使用lettuce作为操作redis的客户端，它使用netty进行网络通信
    //2).lettuce的bug导致netty堆外内存溢出，netty如果没有指定堆外内存，默认使用-xmx默认的内存，没有及时释放内存
    //  可以通过-Dio.netty.maxDirectMemory进行设置
    //解决方案：不能通过-Dio.netty.maxDirectMemory只去调大内存
    //  1)升级lettuce客户端
    //  2)切换使用jedis
    //缓存中拿数据
    @Override
    public Map<String, List<Catelog2Vo>> getCatelogJson() {
        //1.加入缓存逻辑,缓存中存的数据是json字符串,还用逆转为能用的对象类型【序列号与反序列化】
        //json跨语言，跨平台兼容
        String catelogJson = redisTemplate.opsForValue().get("catelogJson");
        if (StringUtils.isEmpty(catelogJson)) {
            //2.缓存中没有，查询数据库
            Map<String, List<Catelog2Vo>> catelogJsonFromDb = getCatelogJsonFromDb();
            //3.查到的数据再放入缓存
            String string = JSON.toJSONString(catelogJsonFromDb);
            redisTemplate.opsForValue().set("catelogJson", string);
            return catelogJsonFromDb;
        }
        //转为我们指定的对象
        Map<String, List<Catelog2Vo>> parseObject = JSON.parseObject(catelogJson, new TypeReference<Map<String, List<Catelog2Vo>>>() {
        });
        return parseObject;
    }
//加入缓存前从数据库查询并封装分类数据
    // @Override
    public Map<String, List<Catelog2Vo>> getCatelogJsonFromDb() {
        List<CategoryEntity> entityList = baseMapper.selectList(null);
        // 查询所有一级分类
        List<CategoryEntity> level1 = getCategoryEntities(entityList, 0L);
        Map<String, List<Catelog2Vo>> parent_cid = level1.stream().collect(Collectors.toMap(k -> k.getCatId().toString(), v -> {
            // 拿到每一个一级分类 然后查询他们的二级分类
            List<CategoryEntity> entities = getCategoryEntities(entityList, v.getCatId());
            List<Catelog2Vo> catelog2Vos = null;
            if (entities != null) {
                catelog2Vos = entities.stream().map(l2 -> {
                    Catelog2Vo catelog2Vo = new Catelog2Vo(v.getCatId().toString(), l2.getName(), l2.getCatId().toString(), null);
                    // 找当前二级分类的三级分类
                    List<CategoryEntity> level3 = getCategoryEntities(entityList, l2.getCatId());
                    // 三级分类有数据的情况下
                    if (level3 != null) {
                        List<Catalog3Vo> catalog3Vos = level3.stream().map(l3 -> new Catalog3Vo(l3.getCatId().toString(), l3.getName(), l2.getCatId().toString())).collect(Collectors.toList());
                        catelog2Vo.setCatalog3List(catalog3Vos);
                    }
                    return catelog2Vo;
                }).collect(Collectors.toList());
            }
            return catelog2Vos;
        }));
        return parent_cid;
    }

```

### 二、缓存失效问题

#### 1、缓存穿透

```
缓存穿透是指 查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查询的 null 写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

在流量大时，可能 DB 就挂掉了，要是有人利用不存在的 key 频繁攻击我们的应用，这就是漏洞。

解决方法：缓存空结果、并且设置短的过期时间。

```

#### 2、缓存雪崩

```
缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到 DB，DB 瞬时压力过重雪崩。

解决方法：原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
```

#### 3、缓存击穿

```
对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。

这个时候，需要考虑一个问题：如果这个 key 在大量请求同时进来前正好失效，那么所有对这个 key 的数据查询都落到 db，我们称为缓存击穿。

解决方法：加锁。大量并发只让一个人去查，其他人等待，查到之后释放锁，其他人获取到锁，先查缓存，就会有数据，不用去查数据库。

如：单体应用中加锁
```

```java
    //缓存中拿数据
    @Override
    public Map<String, List<Catelog2Vo>> getCatelogJson() {
        //1.加入缓存逻辑,缓存中存的数据是json字符串,还用逆转为能用的对象类型【序列号与反序列化】
        //json跨语言，跨平台兼容
        /**
         * 1.空结果缓存，解决缓存穿透
         * 2.设置过期时间，加随机值，解决缓存雪崩
         * 3.加锁，解决缓存击穿
         **/
        String catelogJson = redisTemplate.opsForValue().get("catelogJson");
        if (StringUtils.isEmpty(catelogJson)) {
            //2.缓存中没有，查询数据库
            Map<String, List<Catelog2Vo>> catelogJsonFromDb = getCatelogJsonFromDb();
            //3.查到的数据再放入缓存   这个操作再getCatelogJsonFromDb()完成
            return catelogJsonFromDb;
        }
        //转为我们指定的对象
        Map<String, List<Catelog2Vo>> parseObject = JSON.parseObject(catelogJson, new TypeReference<Map<String, List<Catelog2Vo>>>() {
        });
        return parseObject;
    } 
//加入缓存前从数据库查询并封装分类数据
    // @Override
    public Map<String, List<Catelog2Vo>> getCatelogJsonFromDb() {

        //只要是同一把锁，就能锁住需要这个锁的所有线程
        //1).synchronized (this),SpringBoot所有的组件在容器中都是单例的
        //TODO 本地锁，synchronized (this)，JUC（lock），在分布式情况下，想要锁住所有，我们必须使用分布式锁
        synchronized (this) {

            //得到锁以后，再去缓存中确定一次，如果有了就不用查数据库了
            String catelogJson = redisTemplate.opsForValue().get("catelogJson");
            if (!StringUtils.isEmpty(catelogJson)) {
                Map<String, List<Catelog2Vo>> parseObject = JSON.parseObject(catelogJson, new TypeReference<Map<String, List<Catelog2Vo>>>() {
                });
                return parseObject;
            }

            List<CategoryEntity> entityList = baseMapper.selectList(null);
            // 查询所有一级分类
            List<CategoryEntity> level1 = getCategoryEntities(entityList, 0L);
            Map<String, List<Catelog2Vo>> parent_cid = level1.stream().collect(Collectors.toMap(k -> k.getCatId().toString(), v -> {
                // 拿到每一个一级分类 然后查询他们的二级分类
                List<CategoryEntity> entities = getCategoryEntities(entityList, v.getCatId());
                List<Catelog2Vo> catelog2Vos = null;
                if (entities != null) {
                    catelog2Vos = entities.stream().map(l2 -> {
                        Catelog2Vo catelog2Vo = new Catelog2Vo(v.getCatId().toString(), l2.getName(), l2.getCatId().toString(), null);
                        // 找当前二级分类的三级分类
                        List<CategoryEntity> level3 = getCategoryEntities(entityList, l2.getCatId());
                        // 三级分类有数据的情况下
                        if (level3 != null) {
                            List<Catalog3Vo> catalog3Vos = level3.stream().map(l3 -> new Catalog3Vo(l3.getCatId().toString(), l3.getName(), l2.getCatId().toString())).collect(Collectors.toList());
                            catelog2Vo.setCatalog3List(catalog3Vos);
                        }
                        return catelog2Vo;
                    }).collect(Collectors.toList());
                }
                return catelog2Vos;
            }));
            String string = JSON.toJSONString(parent_cid);
            redisTemplate.opsForValue().set("catelogJson", string,1, TimeUnit.DAYS);
            return parent_cid;
        }
    }

```

### 三、分布式锁

本地锁只能锁住当前服务的进程，每一个单独的服务都会有一个进程读取数据库，不能达到只读取依次数据库的效果，所以需要分布式锁。

![image-20220609102336364](C:\Users\v_lulvli\AppData\Roaming\Typora\typora-user-images\image-20220609102336364.png)

分布式锁的实现

![img](https://raw.githubusercontent.com/lilu188011/img-repo/master/f99a8a45f3cb4f2f951f3a4f29c6daaf.gif)

#### 使用 Redis 作为分布式锁

redis 中有一个 SETNX 命令，该命令会向 redis 中保存一条数据，如果不存在则保存成功，存在则返回失败。

我们约定保存成功即为加锁成功，之后加锁成功的线程才能执行真正的业务操作。

```java

    //加入缓存前从数据库查询并封装分类数据,使用redis占坑实现分布式锁
    public Map<String, List<Catelog2Vo>> getCatelogJsonFromDbWithRedisLock() {
        //1.占分布式锁，  去redis占坑
        //2.设置过期时间（必须和加锁是同步的，院子的）,避免删除锁的时候宕机造成死锁
        String uuid = UUID.randomUUID().toString();//使用随机避免删了别人的锁
        Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid, 300, TimeUnit.SECONDS);
        if (lock) {
            // 加锁成功...执行业务
            Map<String, List<Catelog2Vo>> fromDb;
            try {
                fromDb = getFromDb();
            } finally {
                //获取值对比和对比成功删除要是原子操作
                // String lock1 = redisTemplate.opsForValue().get("lock");
         /* ①原方式  if (uuid.equals(lock1)) {
                //删除我自己的锁
                redisTemplate.delete("lock");//删除锁
            }*/

                //lua 脚本解锁
                String script = "if redis.call(\"get\",KEYS[1]) == ARGV[1] then return redis.call(\"del\",KEYS[1]) else return 0 end";
                // ②改进方式，删除锁
                Long lock2 = redisTemplate.execute(new DefaultRedisScript<Long>(script, Long.class), Arrays.asList("lock"), uuid);
            }
            return fromDb;
        } else {
            //加锁失败。。。重试 synchronize（）
            //休眠100ms重试
            try {
                TimeUnit.MILLISECONDS.sleep(100);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return getCatelogJsonFromDbWithRedisLock();//自旋的方式
        }
    }

```

#### Redisson 作为分布式锁

Redisson是架设在Redis基础上的一个Java驻内存数据网格（In-MemoryDataGrid）。充分的利用了Redis键值数据库提供的一系列优势，基于Java实用工具包中常用接口，为使用者提供了一系列具有分布式特性的常用工具类。使得原本作为协调单机多线程并发程序的工具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统的难度。同时结合各富特色的分布式服务，更进一步简化了分布式环境中程序相互之间的协作。

官方文档：https://github.com/redisson/redisson/wiki

##### 1) 引入依赖

```xml
 <dependency>
   <groupId>org.redisson</groupId>
   <artifactId>redisson</artifactId>
   <version>3.11.1</version>
</dependency>

```

##### 2) 配置 redisson

```
import org.redisson.Redisson;
import org.redisson.api.RedissonClient;
import org.redisson.config.Config;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.io.IOException;

@Configuration
public class MyRedissonConfig {

    /**
     * @Author chenfl
     * @Description //所有对redisson的使用都要通过 RedissonClient 对象
     * @Date 19:36 2022/2/28
     * @Param []
     * @return org.redisson.api.RedissonClient
     **/
    @Bean(destroyMethod="shutdown")
    public RedissonClient redisson() throws IOException {
        //1.创建配置
        //Redis url should start with redis:// or rediss://
        Config config = new Config();
        config.useSingleServer().setAddress("redis://192.168.56.10:6379");
        //2.根据Config创建出RedissonClient
        return Redisson.create(config);
    }

}
```

##### 3) 使用

```java
  public String hello() {
        // 1. 获取一把锁,只要锁的名字是一样,就是同一把锁
        RLock mylock = redisson.getLock("my-lock");
        // 2. 加锁,阻塞式等待
        /**
         * 方式一加锁
         * 1).锁的自动续期，如果业务超长，运行期间自动给锁续上30s,不用担心业务时间长，锁自动过期被删除
         * 2).加锁的业务只要运行完成，就不会给当前的锁续期，及时不手动解锁
         **/
        // mylock.lock();

        /**
         * 方式二加锁
         * 10s自动解锁后，自动解锁时间一定要大于业务的执行时间。
         * 问题：在锁时间到了以后，不会自动续期
         * 1.如果我们传递了锁的超时时间，就发送给redis执行脚本，进行占锁，默认超时就是我们指定的时间
         * 2.如果我们未指定锁的超时时间，就使用30*1000【lockWatchdogTimeout看门狗的默认时间】
         * 只要占锁成功，就会启动一个定时任务【重新给锁设置过期时间，新的过期时间就是看门狗的默认时间】 每隔10s都会再次续期，续成满时间如当前是30s
         * internalLockLeaseTime【看门狗时间】/3......10s
         * 、、
         * //最佳实现
         * 1）mylock.lock(10, TimeUnit.SECONDS);省掉了整个续期的操作，手动解锁
         **/
        mylock.lock(10, TimeUnit.SECONDS);

        try {
            System.out.println("加锁成功，执行业务。。。" + Thread.currentThread().getId());
            //休眠方便测试
            TimeUnit.MILLISECONDS.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            // 3. 解锁,假设解锁代码没有运行，Redisson 会出现死锁吗？（不会）
            System.out.println("释放锁。。。" + Thread.currentThread().getId());
            mylock.unlock();
        }
        return "hello";
    }

```

- 锁的自动续期，如果业务时间很长，运行期间自动给锁续期 30 s，不用担心业务时间过长，锁自动过期被删掉；
- 加锁的业务只要运行完成，就不会给当前锁续期，即使不手动续期，默认也会在 30 s 后解锁；

#### 读写锁

```java
 //保证一定能读到最新的数据。修改期间，写锁是一个排它锁（互斥锁，独享锁），读锁是一个共享锁
    //读+读   相当于无所，并发读，只会在redis中记录好，所有当前的读锁，他们都会同事加锁成功
    //写+读   写锁没释放，读就必须等待
    //写+写   阻塞方式
    //读+写   有读锁，写也需要等待
    //只要有写的存在，都必须等待
    @ResponseBody
    @GetMapping("/write")
    public String write() {

        RReadWriteLock readWriteLock = redisson.getReadWriteLock("rw-lock");
        String s = "";
        RLock rLock = readWriteLock.writeLock();
        try {
            System.out.println("写锁加锁成功" + Thread.currentThread().getId());
            //1.改数据加写锁，读数据加读锁
            rLock.lock();
            s = UUID.randomUUID().toString();
            redisTemplate.opsForValue().set("writeValue", s);
            TimeUnit.SECONDS.sleep(30);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            rLock.unlock();
            System.out.println("写锁释放" + Thread.currentThread().getId());
        }
        return s;
    }

    @ResponseBody
    @GetMapping("/read")
    public String read() {
        RReadWriteLock readWriteLock = redisson.getReadWriteLock("rw-lock");
        String writeValue = null;
        //加读锁
        RLock rLock = readWriteLock.readLock();
        rLock.lock();
        try {
            System.out.println("读锁加锁成功" + Thread.currentThread().getId());
            writeValue = redisTemplate.opsForValue().get("writeValue");
            TimeUnit.SECONDS.sleep(30);
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            rLock.unlock();
            System.out.println("读锁释放" + Thread.currentThread().getId());
        }
        return writeValue;
    }

```

#### 闭锁

```java
    /**
     * @Author chenfl
     * @Description //放假，锁门
     * 1班没人了。。。2班。。。5个班全部走完，我们可以锁大门
     * @Date 9:49 2022/3/1
     * @Param []
     * @return java.lang.String
     **/
    @ResponseBody
    @GetMapping("/lockDoor")
    public String lockDoor() throws InterruptedException {
        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.trySetCount(5);
        door.await();//等待闭锁都完成
        return "放假了。。。";
    }

    @ResponseBody
    @GetMapping("/gogogo/{id}")
    public String gogogo(@PathVariable("id") long id) {
        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.countDown();//计数减一
        return id + "班的人都走了";
    }

```

#### 信号量

```java
 /**
     * @return
     * @Author chenfl
     * @Description //车库停车
     * 3个车位
     * 信号量也可以用作分布式限流
     * @Date 9:58 2022/3/1
     * @Param
     **/
    @ResponseBody
    @GetMapping("/park")
    public String park() throws InterruptedException {
        RSemaphore park = redisson.getSemaphore("park");
        // park.acquire();//获取一个信号，获取一个值,占一个车位
        boolean b = park.tryAcquire();//尝试获取
        if (b) {
            //执行业务
        } else {
            return "当前流量过大，请稍等";
        }
        return "ok=>" + b;
    }

    @ResponseBody
    @GetMapping("/go")
    public String go() throws InterruptedException {
        RSemaphore park = redisson.getSemaphore("park");
        park.release();//释放一个信号
        return "ok";
    }

```

修改代码

```java
    /**
     * 缓存里的数据如何和数据库的数据保持一致？？
     * 缓存数据一致性
     * 1)、双写模式
     * 2)、失效模式
     *
     * @return
     */
    public Map<String, List<Catalogs2Vo>> getCatalogJsonFromDbWithRedissonLock() {

        //1、占分布式锁。去redis占坑
        //（锁的粒度，越细越快:具体缓存的是某个数据，11号商品） product-11-lock
        //RLock catalogJsonLock = redissonClient.getLock("catalogJson-lock");
        //创建读锁
        RReadWriteLock readWriteLock = redissonClient.getReadWriteLock("catalogJson-lock");

        RLock rLock = readWriteLock.readLock();

        Map<String, List<Catalogs2Vo>> dataFromDb = null;
        try {
            rLock.lock();
            //加锁成功...执行业务
            dataFromDb = getCatalogJsonFromDB();
        } finally {
            rLock.unlock();
        }
        return dataFromDb;
    }

```

#### 缓存数据一致性-解决方案

- 无论是双写模式还是失效模式，都会导致缓存的不一致问题，即多个实例同时更新会出事。怎么办？
  - 如果是用户纬度数据（订单数据，用户数据），这种并发率非常小，不用考虑这个问题，缓存数据加上过期时间，每隔一段时间触发读的主动更新即可
  - 如果是菜单，商品介绍等基础数据，也可以去使用canal订阅binlog的方式
  - 缓存数据+过期时间也足够解决大部分业务对于缓存的要求
  - 通过加锁保证并发读写，写写的时候按顺序排好队，读读无所谓，所以适合使用读写锁、（业务不关心脏数据，允许临时脏数据可忽略）

- 总结
  - 我们能放入缓存的数据本就不应该是实时性，一致性要求超高的，所有缓存数据的时候加上过期时间，保证每天拿到当前最新数据即可
  - 我们不应该福过度设计，增加系统的复杂度
  - 遇到实时性，一致性要求高的数据，就应该查数据库，即使慢点